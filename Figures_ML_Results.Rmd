---
title: "Figures ML Results"
author: "Hannah Metzler"
date: "`r Sys.Date()`"
output: html_document
   df_print: kable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
Sys.setlocale("LC_ALL", 'en_US.UTF-8')
options(scipen=10)
library(tidyverse)
library(ggpubr) #for multiple plots together
require(data.table) #string manipulations 
library(RColorBrewer)
rm(list=ls())
```


```{r figure settings, include=FALSE}
cols = c(rev(brewer.pal(12,"Set3")), "violetred4", "cornflowerblue")
#text size
s=10
# s = 5 #for paper png figures JMIR, 15 within Rstudio or for pdfs
# change F1 to F subscript 1 in figures with facet_wrapt
facet_labels <- as_labeller(c(Precision = "Precision", Recall = "Recall",F1="F[1]"), default = label_parsed)

```

```{r, load format data, results=FALSE, cache=TRUE}
macro <- read.csv("results/Results_macro_model_comparison.csv")
#order of classification tasks
order_tasks = as.vector(unique(macro$Classification.task), mode="expression")
difficulty = as.factor(c(rep("Level 1", 2), rep("Level 2", 3), rep("Level 3", 3), rep("Level 4", 2)))

#format
macro = macro %>% 
  mutate(Model = factor(Model, levels =c("Majority", "Tf-idf","BERT"), labels = c("Majority", "Tf-idf","BERT")), 
         Classification.task = factor(Classification.task, levels = order_tasks, labels = order_tasks),
         Dataset = relevel(factor(Dataset), "Validation"),
         Difficulty =  rep(rep(difficulty, each=3), 2)) #repeat per model (3) and per validation/test set  

#load intra class data
intra <- read.csv("results/Intraclass_performance.csv")  %>% 
   mutate(Model = factor(Model, levels =c("Tf-idf & SVM","BERT"), labels = c("Tf-idf & SVM","BERT")), 
         Classification.task = factor(Classification.task, levels = order_tasks, labels = order_tasks), 
         Difficulty =  c(rep("Level 1", 2*2*2), rep("Level 2", 3*2*2), rep("Level 3", 3*2*2), rep("Level 4", 1*4*2), rep("Level 4", 1*14*2))) %>% #always: variables*category*models(2).
  mutate(Model = fct_recode(Model, "Tf-idf" = "Tf-idf & SVM")) 


# load sample size per category data
ncat = data.table(read.csv("results/sample_size_per_category.csv", na.strings = "NA")) 
ncat = rename_with(ncat, ~gsub(".", "", .x, fixed =T)) #delete all dots
ncat[, c("Train", "train_percent") := tstrsplit(ncat$Trainn, "(", fixed=TRUE)] 
ncat[, c("Validation", "validation_percent") := tstrsplit(ncat$Valn, "(", fixed=TRUE)] 
ncat[, c("Test", "test_percent") := tstrsplit(ncat$Testn, "(", fixed=TRUE)]
ncat[, c("Trainn","Valn", "Testn", "validation_percent", "train_percent", "test_percent"):=NULL]

#delete empty rows
ncat = ncat %>% 
  slice(seq(1,nrow(ncat),2)) %>% 
  rename(Classification.task = Classificationtask) %>% 
  mutate(Classification.task = factor(Classification.task, levels = order_tasks, labels = order_tasks))
```

```{r, load format data, results=FALSE, cache=TRUE}
# format/select data for figures #####

#macro
macro_plot = pivot_longer(macro, cols = c("Precision", "Recall", "F1", "Accuracy"), names_to = "Metric", values_to ="Score") %>% 
  mutate(Metric = factor(Metric, levels = c("Precision", "Recall", "F1", "Accuracy"), labels = c("Precision", "Recall", "F1", "Accuracy")))

#intra
intra_plot = pivot_longer(intra, cols = c("Precision", "Recall", "F1"), names_to = "Metric", values_to ="Score") %>% 
  mutate(Metric = factor(Metric, levels = c("Precision", "Recall", "F1"), labels = c("Precision", "Recall", "F1")), 
         Categories = factor(Categories))

# sample sizes
ncat_plot = pivot_longer(ncat, cols = c("Train", "Validation", "Test"), names_to = "dataset", values_to = "n") %>% 
  mutate(n = as.numeric(n), 
         dataset = as.factor(dataset), 
         Classification.task = as.factor(Classification.task))

#calculate proportion per category across all three datasets (average)
ncat_proportions = ncat_plot %>% 
  group_by(Classification.task, Categories) %>% 
  summarise(total = sum(n)) %>%
  mutate(proportion = total / sum(total)) %>% 
  ungroup()
```
# Number of transcripts per class


## Binary tasks
```{r}
ncat_plot %>% 
    filter(!Classification.task %in% c("Problem vs Solution", "Main focus")) %>% 
  group_by(dataset, Categories) %>% 
  summarise(mean = mean(n), 
            median = median(n),
            min = min(n), 
            max = max(n))
```
## Main focus

```{r}
ncat_plot %>% 
    filter(Classification.task %in% c("Main focus")) %>% 
  group_by(dataset) %>% 
  summarise(mean = mean(n), 
            median = median(n),
            min = min(n), 
            max = max(n))
```



```{r, fig n per category binary tasks, fig.height=2.5, fig.width=7}
df_binary = ncat_proportions %>% 
  filter(!Classification.task %in% c("Problem vs Solution", "Main focus")) %>% 
  droplevels() %>% 
  mutate(Classification.task = recode(Classification.task, "Suicide death"="Suicide\n death",
                                      "Healing story"="Healing\n story",
                                      "Celebrity suicide" = "Celebrity \n suicide", 
                                        "Alternatives to suicide"="Alternatives \n to suicide", 
                                      "Monocausality" = "Mono- \n causality",
                                      "Positive outcome crisis"=  "Positive out- \n come crisis",
                                      "Suicidal ideation" =  "Suicidal \n ideation",
                                      "Enhancing myths" =   "Enhancing \n myths" ))

#make sure this drops all factor levels of the level 4 classification tasks
binary = ggplot(df_binary, aes(x=Categories, y = proportion, fill=Categories, colour=Categories)) +
  geom_bar(stat="identity", position = position_dodge2(width = 0.8))+
  facet_wrap(~Classification.task, nrow=1)+
  scale_fill_manual(values=cols, name="")+
  scale_colour_manual(values=cols, name="")+
  theme_bw() +
  theme(legend.position="none", text=element_text(size=s), plot.margin = margin(rep(0.4,4), unit="cm"), axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 45, hjust=1)) #rotate x-axis tick labels
binary
```
```{r, fig n per category problem solution}
df_ps = ncat_proportions %>% 
  filter(Classification.task %in% c("Problem vs Solution")) %>% 
  droplevels()

#make sure this drops all factor levels of the level 4 classification tasks
ps = ggplot(df_ps, aes(x=Categories, y = proportion, fill=Categories, colour = Categories)) +
  geom_bar(stat="identity", position = position_dodge2(width = 0.8))+
  facet_wrap(~Classification.task, nrow=2)+
  scale_fill_manual(values=cols, name="")+
  scale_colour_manual(values=cols, name="")+
  theme_bw() +
  theme(legend.position="none", text=element_text(size=s), plot.margin = margin(rep(0.4,4), unit="cm"), axis.title.x = element_blank(),
           axis.text.x = element_text(angle = 45, hjust=1)) #rotate x-axis tick labels
```
```{r, fig n per category main focus}
df_mf = ncat_proportions %>% 
  filter(Classification.task %in% c("Main focus"))%>% 
  droplevels()

#make sure this drops all factor levels of the level 4 classification tasks
mf = ggplot(df_mf, aes(x=Categories, y = proportion, fill=Categories, colour = Categories)) +
  geom_bar(stat="identity", position = position_dodge2(width = 0.8))+
  facet_wrap(~Classification.task, nrow=2)+
  scale_fill_manual(values=cols, name="")+
  scale_colour_manual(values=cols, name="")+
  theme_bw() +
  theme(legend.position="none", text=element_text(size=s), plot.margin = margin(rep(0.4,4), unit="cm"), axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 45, hjust=1)) #rotate x-axis tick labels
```

```{r, combined proportion per category figure, fig.width=7, fig.height=5}
combined = ggarrange(
  ggarrange(binary, ncol=1, nrow = 1, common.legend=T, labels=c("A"), legend = "none"),
  ggarrange(ps, mf, ncol=2, nrow = 1, common.legend=T, labels=c("B", "C"), legend = "none", align="hv",widths = c(0.3, 0.7)),
 heights= c(0.45, 0.55), nrow=2, legend = "none"
)
combined
ggsave('./figures/Fig1_prop_per_category_all_datasets.png', combined, width=7, height=5, dpi=300)
```

# Model comparison per task: macro-average

```{r, macro plot, fig.height=4.5, fig.width=7}
plot = ggplot(filter(macro_plot, Dataset == "Test"), aes(x=Metric, y = Score, fill=Model, colour = Model)) + #dataset and variables to plot
  geom_bar(stat="identity", position = position_dodge2(width = 0.8))+
  facet_wrap(Classification.task~Difficulty, ncol=5)+
  scale_fill_manual(values=(cols), name="")+
  scale_colour_manual(values=cols, name="")+
  # coord_cartesian(ylim= c(0.6, 0.80))+ # to zoom in
  theme_bw() +  
  theme(legend.position="top", text=element_text(size=s), plot.margin = margin(rep(0.4,4), unit="cm"), axis.title.x = element_blank(), 
        axis.text.x = element_text(angle = 45, hjust=1)) #rotate x-axis tick labels
plot
# ggsave('./figures/Model_comparison_testset_permetric.png', plot, width=7, height=4.5, dpi=300)
```

## Rank difficulty list macro-F1

```{r}
f1_macro = macro_plot %>% 
  filter(Dataset == "Test" & Metric == "F1" & Model != "Majority") %>% 
  select(-c(Metric, Dataset))

as.data.frame(f1_macro %>%   arrange(desc(Score)))
```


# Compare performance on test and validation data set

```{r, fig.height=8, fig.width=7}
tfidf = ggplot(filter(macro_plot, Model == "Tf-idf"), aes(x=Metric, y = Score, fill=Dataset, colour = Dataset)) + #dataset and variables to plot
  geom_bar(stat="identity", position = position_dodge2(width = 0.8))+
  facet_wrap(~Classification.task, ncol=5)+
  ggtitle("Tf-idf")+
  scale_fill_manual(values=(cols), name="")+
  scale_colour_manual(values=cols, name="")+
  # coord_cartesian(ylim= c(0.5, 0.85))+ # to zoom in
  theme_bw() +  
  theme(legend.position="top", text=element_text(size=s), plot.margin = margin(rep(0.4,4), unit="cm"), axis.title.x = element_blank(), 
        axis.text.x = element_text(angle = 45, hjust=1)) #rotate x-axis tick labels
bert = ggplot(filter(macro_plot, Model == "BERT"), aes(x=Metric, y = Score, fill=Dataset, colour = Dataset)) + #dataset and variables to plot
  geom_bar(stat="identity", position = position_dodge2(width = 0.8))+
  facet_wrap(~Classification.task, ncol=5)+
   ggtitle("BERT")+
  scale_fill_manual(values=cols, name="")+
  scale_colour_manual(values=cols, name="")+
  # coord_cartesian(ylim= c(0.5, 0.85))+ # to zoom in
  theme_bw() +  
  theme(legend.position="top", text=element_text(size=s), plot.margin = margin(rep(0.4,4), unit="cm"), axis.title.x = element_blank(), 
        axis.text.x = element_text(angle = 45, hjust=1)) #rotate x-axis tick labels
combined = ggarrange(tfidf, bert, ncol=1, common.legend=T, labels=c("A", "B"))
combined
ggsave('./figures/test_vs_validation_performance.png', combined, width=7, height=8, dpi=300)
```

# Intra-class performances

## Binary tasks

```{r intraclass figure binary, fig.height=4.5, fig.width=7}
df_binary = intra_plot %>% 
  filter(!Classification.task %in% c("Problem vs Solution", "Main focus"), 
         Metric != "F1") %>% 
  droplevels()
# 
plot_binary =
  ggplot(df_binary, aes(x=Categories, y = Score, fill=Metric:Model, colour=Metric:Model)) + #dataset and variables to plot
  geom_bar(stat="identity", position = position_dodge2(width = 0.8))+
  facet_wrap(~Classification.task, ncol = 4)+
  scale_fill_manual(values=c(cols[2:3], alpha(cols[2:3], 0.5)), name="")+
  scale_colour_manual(values=cols[c(2,3,2,3)], name="")+
  # coord_cartesian(ylim=c(0.2,0.7))+
  # scale_y_continuous(breaks = seq(0, 1, 0.2))+
  theme_bw() +  
  theme(legend.position="top", text=element_text(size=s), plot.margin = margin(rep(0.4,4), unit="cm"), axis.title.x = element_blank())
  # guides(fill=guide_legend(nrow=2,byrow=TRUE))
# plot_binary
```

## Problem vs. solution

```{r, ps intraclass, fig.height=4.5, fig.width=7}
df_ps = intra_plot %>% 
  filter(Classification.task %in% c("Problem vs Solution"),
          Metric != "F1") %>% 
  droplevels()

plot_ps = ggplot(df_ps, aes(x=Categories, y = Score, fill=Metric:Model, colour=Metric:Model)) + #dataset and variables to plot
  geom_bar(stat="identity", position = position_dodge2(width = 0.8))+
  facet_wrap(~Classification.task, nrow=2)+
  scale_fill_manual(values=c(cols[2:3], alpha(cols[2:3], 0.5)), name="")+ #
  scale_colour_manual(values=cols[c(2,3,2,3)], name="")+ #
  theme_bw() +  
  theme(legend.position="top", text=element_text(size=s), plot.margin = margin(rep(0.4,4), unit="cm"), axis.title.x = element_blank(), axis.text.x = element_text(angle = 45, hjust=1))
  # guides(fill=guide_legend(nrow=2,byrow=TRUE))
plot_ps
```

## Main focus

```{r, main focus intraclass, fig.height=4.5, fig.width=7}
df_mf = intra_plot %>% 
  filter(Classification.task %in% c("Main focus"),
          Metric != "F1") %>% 
  droplevels()

plot_mf = ggplot(df_mf, aes(x=Categories, y = Score, fill=Metric:Model, colour=Metric:Model)) + #dataset and variables to plot
  geom_bar(stat="identity", position = position_dodge2(width = 0.8))+
  facet_wrap(~Classification.task, nrow=2)+
  scale_fill_manual(values=c(cols[2:3], alpha(cols[2:3], 0.5)), name="")+ #
  scale_colour_manual(values=cols[c(2,3,2,3)], name="")+ #
  theme_bw() +  
  theme(legend.position="top", text=element_text(size=s), plot.margin = margin(rep(0.4,4), unit="cm"), axis.title.x = element_blank(), axis.text.x = element_text(angle = 45, hjust=1))
  # guides(fill=guide_legend(nrow=2,byrow=TRUE))
plot_mf
# ggsave('./figures/Fig3_intraclass_performance_testset_problem_vs_solution.png', plot, width=7, height=4.5, dpi=300)
```

## Combined plot

```{r, combined intraclass figure, fig.width=7, fig.height=6}
combined = ggarrange(
  ggarrange(plot_binary, ncol=1, nrow = 1, common.legend=T, labels=c("A")),
  ggarrange(plot_ps, plot_mf, ncol=2, nrow = 1, common.legend=T, labels=c("B", "C"), align="hv", widths = c(0.3, 0.7), legend = "none"), 
  heights= c(0.6, 0.4), nrow=2)
combined
ggsave('./figures/Fig3_intraclass_performances.png', combined, width=7, height=6, dpi=300)
```


# Correlation of sample size with intra-class performance

```{r, fig.width=7.5, fig.height=5.5, warning=F}
intra_n = intra_plot %>% 
  inner_join(ncat_proportions) %>% 
  rename(n = "total") %>% 
  select(-c(Difficulty)) %>% 
  filter(Metric != "F1") %>% 
  mutate(Categories = factor(Categories, levels = unique(Categories), labels = unique(Categories)), 
         binary_multiple = recode(Classification.task,"Suicide death" = "binary", "Celebrity suicide" = "binary", "Alternatives to suicide" = "binary",  "Monocausality" = "binary", "Positive outcome crisis"="binary",  "Healing story"="binary", "Suicidal ideation" = "binary",  "Enhancing myths"="binary"))
  # filter(!Classification.task %in% c("Problem vs Solution", "Main focus"))
  # pivot_wider(id_cols = c("Categories", "Model", "n", "proportion"), names_from = "Metric", values_from = "Score")

corrn = ggplot(intra_n)+
  geom_point(aes(x=Score, y=n, color = Categories), size=2.1)+
  facet_grid(Model~Metric)+
  theme_bw()+
  # scale_color_manual(values = c(rep(cols[1:4], times = c(1,1,4, 14))))+
  scale_color_manual(values = c("blue", "red3", "cyan", "gold", "green1","darkgreen", "grey", "violet",  "#A6317DFF", rep("grey", 6), "#671C80FF", rep("grey", 4)))+
 
  labs(y = "Class size n", x = "Performance")+
  theme(text=element_text(size=s+1), plot.margin = margin(rep(0.4,4), unit="cm"))
corrn
# ggsave('./figures/Fig4_correlation_n_performance_multicolors.png', corrn, width=7.5, height=5.2, dpi=300)
```

```{r}

cor.test(~Score+n, data = filter(intra_n, Metric == "Precision" & Model =="Tf-idf"& n>100))
cor.test(~Score+n, data = filter(intra_n, Metric == "Recall" & Model =="Tf-idf"& n>100))

cor.test(~Score+n, data = filter(intra_n, Metric == "Precision" & Model =="BERT" & n>100))
cor.test(~Score+n, data = filter(intra_n, Metric == "Recall" & Model =="BERT"& n>100))
```

